{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final threshold= 10 187 506 6530\n",
      "initial threshold= 10 186 732 7178\n",
      "dict_keys([Num(28), \"Christian\", \"Russia\", \"Middle\", Num(26), \"Federal\", \"N.R.\", \"God\", \"UK\", \"Iran\", Num(2006), \"Wall\", \"Estonia\", \"Egypt\", \"Senate\", \"Republican\", \"Soviet\", \"Palestine\", \"Kurd\", \"Tibet\", Num(25), Num(50000000), Num(3000000), \"Office\", Num(2004), \"Muslim\", Num(1990), \"socialism\", \"II\", \"Department\", Num(3), \"Agency\", Num(0), Num(13), \"al-Qaeda\", Num(7), \"Germany\", \"Union\", \"Occupy\", \"Syria\", \"Democrat\", \"Soltanieh\", Num(1000000), \"War\", \"the\", \"Kashmir\", Num(11), \"1/2\", Num(10000), Num(5), \"Nations\", \"Daily\", Num(23), \"Church\", Num(20), \"England\", Num(14), Num(-1), Num(2007), \"Australia\", Num(22), \"Liberal\", Num(30), \"World\", \"North\", \"Bush\", Num(100000000), \"New\", \"France\", Num(2008), \"A\", \"Israel\", \"East\", \"Conservative\", \"United\", Num(21), Num(1994), Num(100000), \"Party\", Num(2001), \"Asia\", \"Fox\", Num(10), \"News\", \"communism\", \"Albania\", \"The\", Num(1960), \"Arabia\", \"Space\", \"Afghanistan\", \"Spain\", \"Canada\", \"Islamism\", Num(300000000), \"Kong\", \"Fascism\", \"Jordan\", \"Obama\", \"U.S.\", Num(4), \"Vietnam\", \"Earth\", \"Nazism\", \"Moo-hyun\", \"-1\", \"India\", \"Islam\", \"Congress\", \"Ying-jeou\", \"Street\", \"Catholic\", \"National\", Num(2005), \"Wikipedia\", \"America\", \"Thailand\", \"Tea\", \"Saudi\", \"Forces\", \"House\", \"Medicare\", Num(16), Num(15), Num(1000), Num(8), \"Libya\", \"Korea\", \"Amendment\", \"York\", \"Great\", \"West\", \"neo-Nazism\", \"NATO\", \"YouTube\", \"Board\", \"Iraq\", \"Britain\", \"Kingdom\", \"People's\", \"George\", Num(1000000000), \"Romney\", Num(31), \"Barack\", \"Democratic\", \"US\", \"Colombia\", \"Europe\", \"Africa\", Num(19), \"Ministry\", \"Foreign\", \"Taiwan\", \"Scotland\", Num(12), Num(18), Num(2002), Num(1000000000000), \"Newt\", \"States\", Num(5000000), \"Jew\", Num(17), \"Indonesia\", Num(9), Num(+), \"Mexico\", \"Tory\", Num(2), \"Laos\", \"China\", \"Al-Qaeda\", \"Security\", \"Brazil\", \"Myong-Chol\", \"Japan\", \"Ireland\", Num(2003), Num(6), Num(1), \"Pakistan\", Num(100), \"of\", \"Hindu\", \"Parliament\", Num(1980)])\n",
      "\n",
      "dict_keys([Concept(circuit), Concept(harbor), Concept(religious), Concept(first), Concept(central), Concept(peninsula), Concept(expand-99), Concept(figure-99), Concept(strategic), Concept(effect-99), Concept(agency), Concept(parliament), Concept(economic), Concept(cancer), Concept(traditional), Concept(democrat), Concept(wall), Concept(criticism-99), Concept(kingdom), Concept(second), Concept(republic), Concept(union), Concept(league), Concept(medicare), Concept(conventional), Concept(course), Concept(commission), Concept(least), Concept(presidency), Concept(point-99), Concept(council), Concept(coast), Concept(ministry), Concept(ethic)])\n",
      "in final, not in initial 34\n",
      "in initial, not in final 260\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import *\n",
    "import  pickle,pprint\n",
    "from utility.amr import *\n",
    "from utility.pickle_helper import *\n",
    "from utility.constants import *\n",
    "from utility.converter import *\n",
    "\n",
    "re_arrange = lambda d: [[k,d[k][0],d[k][1]] for k in d.keys()]\n",
    "sort_dict = lambda d:sorted(re_arrange(d), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pkl_file = open('non_rule_set', 'rb')\n",
    "\n",
    "data = pickle.load(pkl_file)\n",
    "non_rule_set_initial = data[\"initial_non_rule_set\"]\n",
    "\n",
    "\n",
    "#pprint.pprint (sorted_set)                    \n",
    "threshold = 5\n",
    "\n",
    "non_rule_set = data[\"non_rule_set\"]\n",
    "text_num,high_non_text,low_non_text=unmixe(non_rule_set,threshold)\n",
    "text_num_i,high_non_text_i,low_non_text_i=unmixe(non_rule_set_initial,threshold)\n",
    "print (\"final threshold=\", threshold,len(text_num),len(high_non_text),len(low_non_text))\n",
    "print(\"initial threshold=\",threshold,len(text_num_i),len(high_non_text_i),len(low_non_text_i))\n",
    "print (text_num.keys())\n",
    "def subtract_key(d1,d2):\n",
    "    d1_d2 = dict()\n",
    "    for i in d1.keys():\n",
    "        if not i in d2:\n",
    "            o = d1[i]\n",
    "            ss = [o[0]]\n",
    "            for s in o[1]:\n",
    "                ss.append(\" \".join(s))\n",
    "            d1_d2[i]=ss\n",
    "    return d1_d2\n",
    "d1_d2 = subtract_key(high_non_text,high_non_text_i)\n",
    "d2_d1 = subtract_key(high_non_text_i,high_non_text)\n",
    "#print (d1_d2)\n",
    "print ( )\n",
    "print (d1_d2.keys())\n",
    "print (\"in final, not in initial\",len(d1_d2))\n",
    "#print (d2_d1.keys())\n",
    "print (\"in initial, not in final\",len(d2_d1))\n",
    "#pprint (sort_dict(low_non_text))\n",
    "\n",
    "#final threshold= 10 184 514 6717\n",
    "#initial threshold= 10 184 732 7209\n",
    "\n",
    "#final threshold= 10 184 507 6605\n",
    "#initial threshold= 10 184 734 7213\n",
    "\n",
    "#final threshold= 10 186 514 6549\n",
    "#initial threshold= 10 186 732 7178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import *\n",
    "\n",
    "rl= load_rule(\"rule_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "False\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'12': 2, 'decide': 1}\n",
      "[15, 'lastly , farthest away you can see putian of shenzhen .', \"amman 7 - 29 - 2007 ( a. f. p. ) - the saudi man 's team win the gold medal for the 4x100 meter relay today , sunday , in the last day of the 17 th asian athletics championship hold in the jordanian capital amman .\", \"government in the pro - us gulf state be wary of iran 's nuclear program but be also concern by the united states federal government 's refusal to rule out military action as a last resort .\", \"sisi 's last word be reportedly what happen to me?.\", 'elbaradei state that this be the last chance to build security in the middle east base on trust and cooperation and not on possession of nuclear weapon .', 'hawaii will be the last stop of his nine - day us trip .', 'kohl and yeltsin also discuss the issue of bosnia - herzegovina after attend the ceremony for the withdrawal of the last group of russian troop from germany .', 'ff , thanks for the discussion , i will leave the last post of the evening to you .', 'lastly , i be amazed by your spin on the fact that half of americans do not pay federal income tax .', 'december 26 , 1975 , mao zedong have his 82th birth day , his last one .', 'i think santorum be go to be the last of the \" not romneys \" , and newt have have his moment .', 'the last thing that china want be a weak dollar because that would completely wipe out any chance of a trade surplus from their number one trading partner ... the u.s.', 'finally \" a quarter of all primary school child be muslim \" .', \"it ' a comedy show that have some commentary , stewart would be the last one to say it ' news .\", 'and lastly , with the easter holiday come up , young child will need something to keep them occupy .']\n",
      " \n",
      "[15, 'lastly , farthest away you can see putian of shenzhen .', \"amman 7 - 29 - 2007 ( a. f. p. ) - the saudi man 's team win the gold medal for the 4x100 meter relay today , sunday , in the last day of the 17 th asian athletics championship hold in the jordanian capital amman .\", \"government in the pro - us gulf state be wary of iran 's nuclear program but be also concern by the united states federal government 's refusal to rule out military action as a last resort .\", \"sisi 's last word be reportedly what happen to me?.\", 'elbaradei state that this be the last chance to build security in the middle east base on trust and cooperation and not on possession of nuclear weapon .', 'hawaii will be the last stop of his nine - day us trip .', 'kohl and yeltsin also discuss the issue of bosnia - herzegovina after attend the ceremony for the withdrawal of the last group of russian troop from germany .', 'ff , thanks for the discussion , i will leave the last post of the evening to you .', 'lastly , i be amazed by your spin on the fact that half of americans do not pay federal income tax .', 'december 26 , 1975 , mao zedong have his 82th birth day , his last one .', 'i think santorum be go to be the last of the \" not romneys \" , and newt have have his moment .', 'the last thing that china want be a weak dollar because that would completely wipe out any chance of a trade surplus from their number one trading partner ... the u.s.', 'finally \" a quarter of all primary school child be muslim \" .', \"it ' a comedy show that have some commentary , stewart would be the last one to say it ' news .\", 'and lastly , with the easter holiday come up , young child will need something to keep them occupy .']\n",
      "['While', 'it', 'should', 'have', 'been', 'a', 'disaster', 'relief', 'command', 'that', 'takes', 'overall', 'leadership', ',', 'it', 'has', 'suddenly', 'come', 'face', '-', 'to', '-', 'face', 'with', 'the', 'broad', 'base', 'of', 'disaster', 'victims', ',', 'directly', 'dealing', 'with', 'them', '.'] ['while', 'it', 'should', 'have', 'be', 'a', 'disaster', 'relief', 'command', 'that', 'take', 'overall', 'leadership', ',', 'it', 'have', 'suddenly', 'come', 'face', '-', 'to', '-', 'face', 'with', 'the', 'broad', 'base', 'of', 'disaster', 'victim', ',', 'directly', 'deal', 'with', 'them', '.']\n",
      "amr_to_seq\n",
      "[([('<blank>', 2, -1)], 'Rule_Frame', ':top'), ([('and', 1, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':op1'), ([('it', 1, -1)], 'Rule_Concept', ':ARG0'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1-of'), ([('<blank>', 2, -1)], 'Rule_Concept', ':manner'), ([('<blank>', 2, -1)], 'Rule_Frame', ':op2'), ([('it', 1, -1)], 'Rule_Concept', ':ARG0'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG2'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1-of'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG2'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG0-of'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod')]\n",
      "it it with with\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import *\n",
    "def see(x):\n",
    "    o1 = non_rule_set[x]\n",
    "    ss1 = [o1[0]]\n",
    "    for s in o1[1]:\n",
    "        ss1.append(\" \".join(s))    \n",
    "    o2 = non_rule_set_initial[x]\n",
    "    ss2 = [o2[0]]\n",
    "    for s in o2[1]:\n",
    "        ss2.append(\" \".join(s))\n",
    "    return ss1, ss2\n",
    "\n",
    "#print (len(rl.frame_list))\n",
    "#read_frame(rl.frame_list)\n",
    "amr_t = \"(c / contrast-01 :ARG1 (a / and :op1 (f2 / face-01 :ARG0 (i / it) :ARG1 (v / victim :mod (d4 / disaster) :mod (b2 / base :ARG1-of (b / broad-02))) :manner (s / sudden)) :op2 (d / deal-01 :ARG0 i :ARG2 v :ARG1-of (d3 / direct-02))) :ARG2 (r2 / recommend-01 :ARG1 (c4 / command-02 :ARG1 (r / relieve-01 :ARG1 (d2 / disaster)) :ARG0-of (l / lead-02 :mod (o3 / overall)))))\"\n",
    "amr = AMR(amr_t)   \n",
    "m = [0,0,0,0,0,0,0,0,0]\n",
    "print (checkMatch(\"defend\",\"defense\",m))\n",
    "print (m)\n",
    "c = \"decide\"\n",
    "print (rl.lemma_freq_con[c])\n",
    "#print (rl.frame99(c))\n",
    "#print (\"word\",c,\";lemma\",rl.lemmatize_cheat[c.lower()])\n",
    "c = \"affect-99\" \n",
    "con = Concept(c)\n",
    "con = AMRNumber(\"-1\")\n",
    "print (see(con)[0])\n",
    "print (\" \")\n",
    "print (see(con)[1])\n",
    "\n",
    "sentence = \"While it should have been a disaster relief command that takes overall leadership, it has suddenly come face-to-face with the broad base of disaster victims, directly dealing with them.\"\n",
    "x = nlp(sentence)\n",
    "pos = [i.lemma_ for i in x]\n",
    "snt_token = [i.text for i in x]\n",
    "print (snt_token,pos)\n",
    "rule_ge = rl.apply_all_sentence([i.text for i in x],[i.lemma_ for i in x])\n",
    "print(\"amr_to_seq\")\n",
    "print (amr_to_seq(amr,snt_token,pos,rl,high_non_text))\n",
    "print(snt_token[1],snt_token[14],snt_token[23],snt_token[33])\n",
    "#print (rule_ge)\n",
    "#print (rl.lemmatize_cheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(Concept(byline-99), Concept(byline-99))], [(Concept(publication), Concept(publication))], [(Concept(name), Concept(name))], [('Rule_String', 0)], [('Rule_String', 1)], [('Rule_String', 2)], [(Concept(person), Concept(person))], [(Concept(name), Concept(name))], [('Rule_String', 11)], [('Rule_String', 12)], [('Rule_Frame', 10)], [(Concept(date-entity), Concept(date-entity))], [('Rule_Num', 6)], [('Rule_Num', Num(8))], [(Concept(city), Concept(city))], [(Concept(name), Concept(name))]]\n",
      "(b / byline-91\n",
      "    :ARG0 (p2 / publication\n",
      "        :wiki \"Xinhua_News_Agency\"\n",
      "        :name (n / name\n",
      "            :op1 \"Xinhua\"\n",
      "            :op2 \"News\"\n",
      "            :op3 \"Agency\"))\n",
      "    :ARG1 (p / person\n",
      "        :wiki -\n",
      "        :name (n2 / name\n",
      "            :op1 \"Yongfeng\"\n",
      "            :op2 \"Shi\")\n",
      "        :ARG0-of (r / report-01))\n",
      "    :time (d / date-entity\n",
      "        :month 3\n",
      "        :day 8)\n",
      "    :location (c2 / city\n",
      "        :wiki \"Yichang\"\n",
      "        :name (n3 / name\n",
      "            :op1 \"Yichang\")))\n",
      "['Xinhua', 'News', 'Agency', ',', 'Yichang', ',', 'March', '8th', ',', 'by', 'reporter', 'Yongfeng', 'Shi']\n"
     ]
    }
   ],
   "source": [
    "print(amr_to_seq(amr,snt_token,pos,rl,high_non_text))\n",
    "print (amr)\n",
    "print (snt_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_lemmatize_cheat(rl,non_rule_set):\n",
    "    newdict = dict()\n",
    "    for c in non_rule_set.keys():\n",
    "        if not c.is_constant() :\n",
    "            if c.is_frame():\n",
    "                c_t = re.sub(c.RE_FRAME_NUM,\"\",c.__str__())\n",
    "            else:\n",
    "                c_t = c.__str__()\n",
    "            sentences = non_rule_set[c][1]\n",
    "            non_rule_set[c][1] = []\n",
    "            for tokens in sentences:\n",
    "                matched = False\n",
    "                for t in tokens:\n",
    "                    t = t.lower()\n",
    "                    if checkMatch(t,c_t):\n",
    "                        if rl.add_lemmatize_cheat(t,c_t) or t in rl.lemmatize_cheat:\n",
    "                            matched = True\n",
    "                            print (t,wordnet_lemmatizer.lemmatize(t),c_t,c)\n",
    "                if not matched:\n",
    "                    non_rule_set[c][1].append(\" \".join(tokens))\n",
    "            if len( non_rule_set[c][1]) >0:\n",
    "                newdict[c] = non_rule_set[c]\n",
    "                newdict[c][0] = len(newdict[c][1])\n",
    "        else:\n",
    "            newdict[c] = non_rule_set[c]\n",
    "    return newdict\n",
    "#rl.frame_list[\"gone\"]    \n",
    "newdict = add_lemmatize_cheat(rl,non_rule_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  pickle,pprint\n",
    "\n",
    "re_arrange = lambda d: [[k,d[k][0],[' '.join(s) for s in d[k][1]]] for k in d.keys()]\n",
    "sort_dict = lambda d:sorted(re_arrange(d), key=lambda x: x[1], reverse=True)\n",
    "#pprint.pprint (sorted_set)                    \n",
    "threshold = 50\n",
    "newdict = non_rule_set\n",
    "text_num,high_non_text,low_non_text=unmixe(newdict,threshold)\n",
    "\n",
    "print (\"threshold\\ttotal\\tlennon_rule_set\\ttext_num\\thigh_frequency_concept\\tlow_frequency_concept\")\n",
    "print (str(threshold)+\"\\t\\t\"+str(len(newdict))+\"\\t\"+str(len(text_num))+\"\\t\\t\\t\\t\"+str(len(high_non_text))+\"\\t\\t\\t\"+str(len(low_non_text)))\n",
    "print (\"low_frequency_concept\")\n",
    "\n",
    "pprint.pprint (sort_dict(low_non_text))\n",
    "#pprint.pprint (sort_dict(high_non_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "def checkMatch(s1,s2):\n",
    "    return (1.0*edit_distance(s1,s2)/min(len(s1),len(s2)) < 0.25) \n",
    "print (checkMatch(\"angrily\",\"angry\"))\n",
    "print (checkMatch(\"rediculousness\",\"ridiculous\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
