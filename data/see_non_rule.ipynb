{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.8.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2c42679e6578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mpickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/AMR_AS_SRL/npmt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/AMR_AS_SRL/npmt/Dict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_NOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.8.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import *\n",
    "import  pickle,pprint\n",
    "from utility.amr import *\n",
    "from utility.pickle_helper import *\n",
    "from utility.constants import *\n",
    "from utility.converter import *\n",
    "\n",
    "re_arrange = lambda d: [[k,d[k][0],d[k][1]] for k in d.keys()]\n",
    "sort_dict = lambda d:sorted(re_arrange(d), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pkl_file = open('non_rule_set', 'rb')\n",
    "\n",
    "data = pickle.load(pkl_file)\n",
    "non_rule_set_initial = data[\"initial_non_rule_set\"]\n",
    "\n",
    "\n",
    "#pprint.pprint (sorted_set)                    \n",
    "threshold = 5\n",
    "\n",
    "non_rule_set = data[\"non_rule_set\"]\n",
    "text_num,high_non_text,low_non_text=unmixe(non_rule_set,threshold)\n",
    "text_num_i,high_non_text_i,low_non_text_i=unmixe(non_rule_set_initial,threshold)\n",
    "print (\"final threshold=\", threshold,len(text_num),len(high_non_text),len(low_non_text))\n",
    "print(\"initial threshold=\",threshold,len(text_num_i),len(high_non_text_i),len(low_non_text_i))\n",
    "print (text_num.keys())\n",
    "def subtract_key(d1,d2):\n",
    "    d1_d2 = dict()\n",
    "    for i in d1.keys():\n",
    "        if not i in d2:\n",
    "            o = d1[i]\n",
    "            ss = [o[0]]\n",
    "            for s in o[1]:\n",
    "                ss.append(\" \".join(s))\n",
    "            d1_d2[i]=ss\n",
    "    return d1_d2\n",
    "d1_d2 = subtract_key(high_non_text,high_non_text_i)\n",
    "d2_d1 = subtract_key(high_non_text_i,high_non_text)\n",
    "#print (d1_d2)\n",
    "print ( )\n",
    "print (d1_d2.keys())\n",
    "print (\"in final, not in initial\",len(d1_d2))\n",
    "#print (d2_d1.keys())\n",
    "print (\"in initial, not in final\",len(d2_d1))\n",
    "\n",
    "print (text_num.keys())\n",
    "print (high_non_text.keys())\n",
    "#pprint (sort_dict(low_non_text))\n",
    "\n",
    "#final threshold= 10 184 514 6717\n",
    "#initial threshold= 10 184 732 7209\n",
    "\n",
    "#final threshold= 10 184 507 6605\n",
    "#initial threshold= 10 184 734 7213\n",
    "\n",
    "#final threshold= 10 186 514 6549\n",
    "#initial threshold= 10 186 732 7178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['program']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-50a9ef6e5df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"programs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_freq_con\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_freq_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rl' is not defined"
     ]
    }
   ],
   "source": [
    "c = \"prison\"\n",
    "x = nlp(\"programs\")\n",
    "print ([i.lemma_ for i in x])\n",
    "print (rl.lemma_freq_con[c])\n",
    "print (rl.lemma_freq_frame[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libcudart.so.8.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e686ab01cbe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrl\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mload_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rule_f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/AMR_AS_SRL/npmt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnpmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/AMR_AS_SRL/npmt/Dict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/afs/inf.ed.ac.uk/user/s15/s1544871/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_NOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: libcudart.so.8.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import load_rule\n",
    "\n",
    "rl= load_rule(\"rule_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "False\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'12': 2, 'decide': 1}\n",
      "[15, 'lastly , farthest away you can see putian of shenzhen .', \"amman 7 - 29 - 2007 ( a. f. p. ) - the saudi man 's team win the gold medal for the 4x100 meter relay today , sunday , in the last day of the 17 th asian athletics championship hold in the jordanian capital amman .\", \"government in the pro - us gulf state be wary of iran 's nuclear program but be also concern by the united states federal government 's refusal to rule out military action as a last resort .\", \"sisi 's last word be reportedly what happen to me?.\", 'elbaradei state that this be the last chance to build security in the middle east base on trust and cooperation and not on possession of nuclear weapon .', 'hawaii will be the last stop of his nine - day us trip .', 'kohl and yeltsin also discuss the issue of bosnia - herzegovina after attend the ceremony for the withdrawal of the last group of russian troop from germany .', 'ff , thanks for the discussion , i will leave the last post of the evening to you .', 'lastly , i be amazed by your spin on the fact that half of americans do not pay federal income tax .', 'december 26 , 1975 , mao zedong have his 82th birth day , his last one .', 'i think santorum be go to be the last of the \" not romneys \" , and newt have have his moment .', 'the last thing that china want be a weak dollar because that would completely wipe out any chance of a trade surplus from their number one trading partner ... the u.s.', 'finally \" a quarter of all primary school child be muslim \" .', \"it ' a comedy show that have some commentary , stewart would be the last one to say it ' news .\", 'and lastly , with the easter holiday come up , young child will need something to keep them occupy .']\n",
      " \n",
      "[15, 'lastly , farthest away you can see putian of shenzhen .', \"amman 7 - 29 - 2007 ( a. f. p. ) - the saudi man 's team win the gold medal for the 4x100 meter relay today , sunday , in the last day of the 17 th asian athletics championship hold in the jordanian capital amman .\", \"government in the pro - us gulf state be wary of iran 's nuclear program but be also concern by the united states federal government 's refusal to rule out military action as a last resort .\", \"sisi 's last word be reportedly what happen to me?.\", 'elbaradei state that this be the last chance to build security in the middle east base on trust and cooperation and not on possession of nuclear weapon .', 'hawaii will be the last stop of his nine - day us trip .', 'kohl and yeltsin also discuss the issue of bosnia - herzegovina after attend the ceremony for the withdrawal of the last group of russian troop from germany .', 'ff , thanks for the discussion , i will leave the last post of the evening to you .', 'lastly , i be amazed by your spin on the fact that half of americans do not pay federal income tax .', 'december 26 , 1975 , mao zedong have his 82th birth day , his last one .', 'i think santorum be go to be the last of the \" not romneys \" , and newt have have his moment .', 'the last thing that china want be a weak dollar because that would completely wipe out any chance of a trade surplus from their number one trading partner ... the u.s.', 'finally \" a quarter of all primary school child be muslim \" .', \"it ' a comedy show that have some commentary , stewart would be the last one to say it ' news .\", 'and lastly , with the easter holiday come up , young child will need something to keep them occupy .']\n",
      "['While', 'it', 'should', 'have', 'been', 'a', 'disaster', 'relief', 'command', 'that', 'takes', 'overall', 'leadership', ',', 'it', 'has', 'suddenly', 'come', 'face', '-', 'to', '-', 'face', 'with', 'the', 'broad', 'base', 'of', 'disaster', 'victims', ',', 'directly', 'dealing', 'with', 'them', '.'] ['while', 'it', 'should', 'have', 'be', 'a', 'disaster', 'relief', 'command', 'that', 'take', 'overall', 'leadership', ',', 'it', 'have', 'suddenly', 'come', 'face', '-', 'to', '-', 'face', 'with', 'the', 'broad', 'base', 'of', 'disaster', 'victim', ',', 'directly', 'deal', 'with', 'them', '.']\n",
      "amr_to_seq\n",
      "[([('<blank>', 2, -1)], 'Rule_Frame', ':top'), ([('and', 1, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':op1'), ([('it', 1, -1)], 'Rule_Concept', ':ARG0'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1-of'), ([('<blank>', 2, -1)], 'Rule_Concept', ':manner'), ([('<blank>', 2, -1)], 'Rule_Frame', ':op2'), ([('it', 1, -1)], 'Rule_Concept', ':ARG0'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG2'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1-of'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG2'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Concept', ':ARG1'), ([('<blank>', 2, -1)], 'Rule_Frame', ':ARG0-of'), ([('<blank>', 2, -1)], 'Rule_Concept', ':mod')]\n",
      "it it with with\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from npmt.rules import *\n",
    "def see(x):\n",
    "    o1 = non_rule_set[x]\n",
    "    ss1 = [o1[0]]\n",
    "    for s in o1[1]:\n",
    "        ss1.append(\" \".join(s))    \n",
    "    o2 = non_rule_set_initial[x]\n",
    "    ss2 = [o2[0]]\n",
    "    for s in o2[1]:\n",
    "        ss2.append(\" \".join(s))\n",
    "    return ss1, ss2\n",
    "\n",
    "#print (len(rl.frame_list))\n",
    "#read_frame(rl.frame_list)\n",
    "amr_t = \"(c / contrast-01 :ARG1 (a / and :op1 (f2 / face-01 :ARG0 (i / it) :ARG1 (v / victim :mod (d4 / disaster) :mod (b2 / base :ARG1-of (b / broad-02))) :manner (s / sudden)) :op2 (d / deal-01 :ARG0 i :ARG2 v :ARG1-of (d3 / direct-02))) :ARG2 (r2 / recommend-01 :ARG1 (c4 / command-02 :ARG1 (r / relieve-01 :ARG1 (d2 / disaster)) :ARG0-of (l / lead-02 :mod (o3 / overall)))))\"\n",
    "amr = AMR(amr_t)   \n",
    "m = [0,0,0,0,0,0,0,0,0]\n",
    "print (checkMatch(\"defend\",\"defense\",m))\n",
    "print (m)\n",
    "c = \"decide\"\n",
    "print (rl.lemma_freq_con[c])\n",
    "#print (rl.frame99(c))\n",
    "#print (\"word\",c,\";lemma\",rl.lemmatize_cheat[c.lower()])\n",
    "c = \"affect-99\" \n",
    "con = Concept(c)\n",
    "con = AMRNumber(\"-1\")\n",
    "print (see(con)[0])\n",
    "print (\" \")\n",
    "print (see(con)[1])\n",
    "\n",
    "sentence = \"While it should have been a disaster relief command that takes overall leadership, it has suddenly come face-to-face with the broad base of disaster victims, directly dealing with them.\"\n",
    "x = nlp(sentence)\n",
    "pos = [i.lemma_ for i in x]\n",
    "snt_token = [i.text for i in x]\n",
    "print (snt_token,pos)\n",
    "rule_ge = rl.apply_all_sentence([i.text for i in x],[i.lemma_ for i in x])\n",
    "print(\"amr_to_seq\")\n",
    "print (amr_to_seq(amr,snt_token,pos,rl,high_non_text))\n",
    "print(snt_token[1],snt_token[14],snt_token[23],snt_token[33])\n",
    "#print (rule_ge)\n",
    "#print (rl.lemmatize_cheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(Concept(byline-99), Concept(byline-99))], [(Concept(publication), Concept(publication))], [(Concept(name), Concept(name))], [('Rule_String', 0)], [('Rule_String', 1)], [('Rule_String', 2)], [(Concept(person), Concept(person))], [(Concept(name), Concept(name))], [('Rule_String', 11)], [('Rule_String', 12)], [('Rule_Frame', 10)], [(Concept(date-entity), Concept(date-entity))], [('Rule_Num', 6)], [('Rule_Num', Num(8))], [(Concept(city), Concept(city))], [(Concept(name), Concept(name))]]\n",
      "(b / byline-91\n",
      "    :ARG0 (p2 / publication\n",
      "        :wiki \"Xinhua_News_Agency\"\n",
      "        :name (n / name\n",
      "            :op1 \"Xinhua\"\n",
      "            :op2 \"News\"\n",
      "            :op3 \"Agency\"))\n",
      "    :ARG1 (p / person\n",
      "        :wiki -\n",
      "        :name (n2 / name\n",
      "            :op1 \"Yongfeng\"\n",
      "            :op2 \"Shi\")\n",
      "        :ARG0-of (r / report-01))\n",
      "    :time (d / date-entity\n",
      "        :month 3\n",
      "        :day 8)\n",
      "    :location (c2 / city\n",
      "        :wiki \"Yichang\"\n",
      "        :name (n3 / name\n",
      "            :op1 \"Yichang\")))\n",
      "['Xinhua', 'News', 'Agency', ',', 'Yichang', ',', 'March', '8th', ',', 'by', 'reporter', 'Yongfeng', 'Shi']\n"
     ]
    }
   ],
   "source": [
    "print(amr_to_seq(amr,snt_token,pos,rl,high_non_text))\n",
    "print (amr)\n",
    "print (snt_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_lemmatize_cheat(rl,non_rule_set):\n",
    "    newdict = dict()\n",
    "    for c in non_rule_set.keys():\n",
    "        if not c.is_constant() :\n",
    "            if c.is_frame():\n",
    "                c_t = re.sub(c.RE_FRAME_NUM,\"\",c.__str__())\n",
    "            else:\n",
    "                c_t = c.__str__()\n",
    "            sentences = non_rule_set[c][1]\n",
    "            non_rule_set[c][1] = []\n",
    "            for tokens in sentences:\n",
    "                matched = False\n",
    "                for t in tokens:\n",
    "                    t = t.lower()\n",
    "                    if checkMatch(t,c_t):\n",
    "                        if rl.add_lemmatize_cheat(t,c_t) or t in rl.lemmatize_cheat:\n",
    "                            matched = True\n",
    "                            print (t,wordnet_lemmatizer.lemmatize(t),c_t,c)\n",
    "                if not matched:\n",
    "                    non_rule_set[c][1].append(\" \".join(tokens))\n",
    "            if len( non_rule_set[c][1]) >0:\n",
    "                newdict[c] = non_rule_set[c]\n",
    "                newdict[c][0] = len(newdict[c][1])\n",
    "        else:\n",
    "            newdict[c] = non_rule_set[c]\n",
    "    return newdict\n",
    "#rl.frame_list[\"gone\"]    \n",
    "newdict = add_lemmatize_cheat(rl,non_rule_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import  pickle,pprint\n",
    "\n",
    "re_arrange = lambda d: [[k,d[k][0],[' '.join(s) for s in d[k][1]]] for k in d.keys()]\n",
    "sort_dict = lambda d:sorted(re_arrange(d), key=lambda x: x[1], reverse=True)\n",
    "#pprint.pprint (sorted_set)                    \n",
    "threshold = 50\n",
    "newdict = non_rule_set\n",
    "text_num,high_non_text,low_non_text=unmixe(newdict,threshold)\n",
    "\n",
    "print (\"threshold\\ttotal\\tlennon_rule_set\\ttext_num\\thigh_frequency_concept\\tlow_frequency_concept\")\n",
    "print (str(threshold)+\"\\t\\t\"+str(len(newdict))+\"\\t\"+str(len(text_num))+\"\\t\\t\\t\\t\"+str(len(high_non_text))+\"\\t\\t\\t\"+str(len(low_non_text)))\n",
    "print (\"low_frequency_concept\")\n",
    "\n",
    "pprint.pprint (sort_dict(low_non_text))\n",
    "#pprint.pprint (sort_dict(high_non_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.metrics.distance import edit_distance\n",
    "def checkMatch(s1,s2):\n",
    "    return (1.0*edit_distance(s1,s2)/min(len(s1),len(s2)) < 0.25) \n",
    "print (checkMatch(\"angrily\",\"angry\"))\n",
    "print (checkMatch(\"rediculousness\",\"ridiculous\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
